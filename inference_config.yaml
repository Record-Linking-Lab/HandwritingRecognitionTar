# INFERENCE CONFIGURATION FILE

# The path to the images to be inferred
img_path: ./data/example/test_images
# The output path to the results of the inference
out_path: ./data/example/iam_inference.csv
# Specify the recognition architecture. Available: ['flor', 'gtr']
recognition_architecture: flor
# If using the gtr architecture, you can specify the number of filters here for each gateblock
gateblock_filters: 512
# The path to the pre-trained model weights to be used during inference
model_in: ./data/model_weights/example_model/run1
# The size which all images will be resized/padded for inference on the model
img_size: (64, 1024)
# The batch size to be used when performing inference on the model (how many images will be inferred at once)
batch_size: 32
# The max number of characters in a line-level transcription
max_seq_size: 128
# Whether or not to print the inference results to the console and show images - Useful for debugging
console_out: False
# String including the character set for the model (charset: abcd1234) If no characters are specified, the default is used.
charset:

# Whether or not to use the Word Beam Search decoding algorithm (Note that all parameters following 'use_wbs' are only
# required when use_wbs is set to True).
use_wbs: False
# Non-Punctuation character set (wbs_word_charset: 'abcdefABCDEF'). If not characters are specified, the default is used.
wbs_word_charset:
# Beam width use for wbs algorithm
wbs_beam_width: 25
# Operating System type ['mac', 'linux'] Windows not supported for Word Beam Search
wbs_os_type: mac
# Whether or not to include GPU support for Word Beam Search Custom Op
wbs_gpu: False
# Whether or not to use 8 threads when decoding model output matrix
wbs_multithreaded: False