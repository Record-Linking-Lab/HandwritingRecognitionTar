# INFERENCE CONFIGURATION FILE

# The path to the images to be inferred
img_path: ./data/example/test_images
# Include subdirectories of img_path, if set to False any directories within img_path will be ignored
img_path_subdirs: True
# The output path to the results of the inference
out_path: ./data/example/iam_inference.csv
# Specify the recognition architecture. Available: ['flor', 'gtr']
recognition_architecture: flor
# If using the gtr architecture, you can specify the number of filters here for each standard gateblock
std_gateblock_filters: 512
# If using the gtr architecture, you can specify the number of filters here for each pooling gateblock
pooling_gateblock_filters: 128
# If using the gtr architecture, you can specify the number of gateblocks required in the architecture
num_gateblocks: 7
# If using the gtr architecture, you can specify at which height the feature map must be when it is collapsed by avg pooling
avg_pool_height: 2
# The path to the pre-trained model weights to be used during inference
model_in: ./data/model_weights/example_model/run1
# The size which all images will be resized/padded for inference on the model
img_size: (64, 1024)
# The batch size to be used when performing inference on the model (how many images will be inferred at once)
batch_size: 32
# The max number of characters in a line-level transcription
max_seq_size: 128
# Whether or not to print the inference results to the console and show images - Useful for debugging
console_out: False
# String including the character set for the model (charset: abcd1234) If no characters are specified, the default is used.
charset:

# Whether or not to use the Word Beam Search decoding algorithm (Note that all parameters following 'use_wbs' are only
# required when use_wbs is set to True).
use_wbs: False
# Non-Punctuation character set (wbs_word_charset: '12345'). If not characters are specified, the default is used.
wbs_word_charset:
# Beam width use for wbs algorithm
wbs_beam_width: 15
